<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Cgx by hohoCode</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Cgx</h1>
        <p>UltraFast GPU Grammar Extractor for Statistical Machine Translation</p>

        <p class="view"><a href="https://github.com/hohoCode/cgx">View the Project on GitHub <small>hohoCode/cgx</small></a></p>


        <ul>
          <li><a href="https://github.com/hohoCode/cgx/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/hohoCode/cgx/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/hohoCode/cgx">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h1>
<a id="cgx" class="anchor" href="#cgx" aria-hidden="true"><span class="octicon octicon-link"></span></a>cgx</h1>

<p>UltraFast GPU Grammar Extractor for Statistical Machine Translation</p>

<h2>
<a id="installation-instruction" class="anchor" href="#installation-instruction" aria-hidden="true"><span class="octicon octicon-link"></span></a>INSTALLATION Instruction</h2>

<ul>
<li><p>please download thrust GPU library, which actually just needs git clone and that is it. Address is here: <a href="https://github.com/thrust/thrust">https://github.com/thrust/thrust</a></p></li>
<li><p>Install CUDA library and CUDA driver on your machine. Please follow the instruction on Nvidia website:
<a href="https://developer.nvidia.com/cuda-zone">https://developer.nvidia.com/cuda-zone</a></p></li>
<li><p>This program requires the GPU device to have at least 4GB GPU memory. The codes work with Kephler/Fermi/pre-Fermi architecture GPUs.</p></li>
<li><p>In provided MAKEFILE file, we have:</p></li>
</ul>

<pre><code>NVCC =nvcc -arch=compute_35 -code=sm_35
CUDA_INSTALL_PATH= /opt/common/cuda/cuda-5.5.22
OPT = -O3 -I./uthash/ -I/scratch0/huah/thrust/
NVCCFLAGS = $(OPT) -use_fast_math -I. -I$(CUDA_INSTALL_PATH)/include 
</code></pre>

<ul>
<li><p>The above four variables in MAKEFILE need to be updated according to your runnning enviroment. For example, the CUDA library install path ($CUDA_INSTALL_PATH) needs to be set to the corresponding path on your GPU machine; $OPT needs thrust library directory's path; so is the computing version of your GPUs (For example, Tesla K20 is 3.5 therfore it is -arch=compute_35); etc. </p></li>
<li><p>In the main directory please compile the codes as below. Probably you will see lots of warnings please just ignore those as long as there are no errors. If errors that could probably be CUDA library related issues, please update your cuda driver and library to the latest version.</p></li>
</ul>

<pre><code>make
</code></pre>

<ul>
<li>If you can get this executable file under bin/ directory, that means compilation is good:</li>
</ul>

<pre><code>bin/strmatchcuda
</code></pre>

<ul>
<li>Command to run (one example on FBIS parallel data):</li>
</ul>

<pre><code>./bin/strmatchcuda 
fbis.zh 
allqueries.txt.2000 
fbis.en
fbis.aligned 
lex.bin 
gpugrammar_temp
</code></pre>

<ul>
<li>
<p>Please provide the following as input arguments:</p>

<ol>
<li>First argument is the address of source side of parallel corpus.</li>
<li>Second: query file (each line is a query sentence)</li>
<li>Third: target side of your parallel data</li>
<li>Four: alignment file (same format as used in cdec)</li>
<li>Five: lexical bin (which is directly from cdec's precomputation step, just reuse its output for lexical features)</li>
<li>Six: the output directory address. (this is the directory address to hold the output grammar files. Each query will output one grammar file. So all grammars will be in the directory). If this directory does not exist yet please create this directory first.</li>
<li>Note the above example also assumes these files are on the same directory, while actually they can be anywhere just specify the address. All input files are having the format as cdec's grmmmar extxractor.</li>
</ol>
</li>
<li><p>In the end if you see output log is like the below, this means everything has been done and it is in the last printing step ('IO step' as in the paper):</p></li>
</ul>

<pre><code>Start Printing Gappy Phrases...
</code></pre>

<ul>
<li>Once done just go check the gpugrammar_temp directory and there should be bunch of grammar files for queries (one file for each query).</li>
<li>Troubleshooting. Common installation problems are mainly from CUDA memory allocation/access side, causing weido memory problems during running. We encourage you to use the latest GPU driver and CUDA library.</li>
<li>We will further update our codes significantly in our next release to make this code easier to use.. Stay tuned.</li>
</ul>

<p>Thanks.</p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/hohoCode">hohoCode</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>